{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.buzzfeed.com/{}.xml?page={}'\n",
    "categories = ['health', 'tech', 'science', 'politics', 'reader']\n",
    "feed = []\n",
    "\n",
    "for category in categories:\n",
    "    category_feed = []\n",
    "    for page_num in range(1, 6):\n",
    "        entries = feedparser.parse(base_url.format(category, page_num)).entries\n",
    "        for entry in entries:\n",
    "            try:\n",
    "                summary = re.findall('<h1>(.*)<\\/h1>', entry.summary)[0]\n",
    "            except IndexError:\n",
    "                summary = 'NaN'\n",
    "            \n",
    "            try:\n",
    "                category_feed.append({\n",
    "                    'title': entry.title,\n",
    "                    'summary': summary,\n",
    "                    'author': entry.author,\n",
    "                    'link': entry.link,\n",
    "                    'published': entry.published,\n",
    "                })\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    feed.extend(category_feed[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(url):\n",
    "    html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html)\n",
    "    texts = []\n",
    "    \n",
    "    # Parsing text areas\n",
    "    for div in soup.findAll('div', attrs={'class': 'subbuzz-text'}):\n",
    "        for p in div.findAll('p'):\n",
    "            texts.append(p.get_text())\n",
    "    \n",
    "    # Parsing description areas\n",
    "    for div in soup.findAll('div', attrs={'class': 'subbuzz__description'}):\n",
    "        for p in div.findAll('p'):\n",
    "            texts.append(p.get_text())\n",
    "    \n",
    "    # Parsing sub titles\n",
    "    for span in soup.findAll('span', attrs={'class': 'js-subbuzz__title-text'}):\n",
    "        texts.append(span.get_text())\n",
    "        \n",
    "    return ' '.join(texts)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 2000 \n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A year ahead of the US presidential election, the worldâ€™s biggest social media companies are still failing to tackle manipulation on their platforms, an exercise by NATO StratCom has found. To test the ability of Facebook, Twitter, YouTube, and Instagram to detect potentially malicious activity, researchers at the NATO Strategic Communication Centre of Excellence ran a four-month experiment starting in May. They purchased social media engagement on 105 different posts across the four social medi'"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = feed[666]['link']\n",
    "texts = load_text(url)\n",
    "\n",
    "print('Length:', len(texts), '\\nText:')\n",
    "texts[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
