{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import feedparser\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.buzzfeed.com/{}.xml?page={}'\n",
    "categories = ['health', 'tech', 'science', 'politics', 'reader']\n",
    "feed = []\n",
    "\n",
    "for category in categories:\n",
    "    category_feed = []\n",
    "    for page_num in range(1, 6):\n",
    "        entries = feedparser.parse(base_url.format(category, page_num)).entries\n",
    "        for entry in entries:\n",
    "            try:\n",
    "                summary = re.findall('<h1>(.*)<\\/h1>', entry.summary)[0]\n",
    "            except IndexError:\n",
    "                summary = 'NaN'\n",
    "            \n",
    "            try:\n",
    "                category_feed.append({\n",
    "                    'title': entry.title,\n",
    "                    'summary': summary,\n",
    "                    'author': entry.author,\n",
    "                    'link': entry.link,\n",
    "                    'published': entry.published,\n",
    "                })\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    feed.extend(category_feed[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Watching My Cousin’s Death Go Viral',\n",
       " 'summary': 'My cousin Salahuddin was a victim of unforgivable police brutality. But before that, he was a young man let down by a society that still treats mental illness as a kind of crime in itself.',\n",
       " 'author': 'Bilal Anwar',\n",
       " 'link': 'https://www.buzzfeednews.com/article/bilalanwar/pakistan-salahuddin-ayubi-death-police-mental-health',\n",
       " 'published': 'Mon, 06 Jan 2020 18:56:35 -0500'}"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(url):\n",
    "    html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html)\n",
    "    texts = []\n",
    "    \n",
    "    # Parsing text areas\n",
    "    for div in soup.findAll('div', attrs={'class': 'subbuzz-text'}):\n",
    "        for p in div.findAll('p'):\n",
    "            texts.append(p.get_text())\n",
    "    \n",
    "    # Parsing description areas\n",
    "    for div in soup.findAll('div', attrs={'class': 'subbuzz__description'}):\n",
    "        for p in div.findAll('p'):\n",
    "            texts.append(p.get_text())\n",
    "    \n",
    "    # Parsing sub titles\n",
    "    for span in soup.findAll('span', attrs={'class': 'js-subbuzz__title-text'}):\n",
    "        texts.append(span.get_text())\n",
    "        \n",
    "    return ' '.join(texts)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 2000 \n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The date in the grainy video footage says “July 17, 2019, 9:19 p.m.” A man in a muddy brown shalwar kameez enters an ATM booth. He pauses briefly to examine the machine before fiddling with it. As he sticks his finger into the cash slot, he notices the blinking red light of a camera observing him. Defiant, he sticks out his tongue and makes a face, puffing out his cheeks. The man proceeds to pry off the front panel of the ATM and notices a second camera embedded in the machine. He pulls more fac'"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.buzzfeednews.com/article/bilalanwar/pakistan-salahuddin-ayubi-death-police-mental-health'\n",
    "texts = load_text(url)\n",
    "\n",
    "print('Length:', len(texts), '\\nText:')\n",
    "texts[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
