{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vlsnk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "import os, sys\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'imdbEr.txt',\n",
       " 'test',\n",
       " 'test.csv',\n",
       " 'imdb.vocab',\n",
       " 'README',\n",
       " 'train',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the IMBD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.DataFrame(columns=['text', 'target'])\n",
    "data_test = pd.DataFrame(columns=['text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] train 'pos' data loaded\n",
      "[info] train 'neg' data loaded\n",
      "[info] test 'pos' data loaded\n",
      "[info] test 'neg' data loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train data\n",
    "\"\"\"\n",
    "basic_path = os.path.join(*['aclImdb', 'train', 'pos'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_train = data_train.append({\n",
    "            'text': f.read(),\n",
    "            'target': 1\n",
    "        }, ignore_index=True)\n",
    "print('[info] train \\'pos\\' data loaded')\n",
    "        \n",
    "basic_path = os.path.join(*['aclImdb', 'train', 'neg'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_train = data_train.append({\n",
    "            'text': f.read(),\n",
    "            'target': 0\n",
    "        }, ignore_index=True)\n",
    "print('[info] train \\'neg\\' data loaded')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test data\n",
    "\"\"\"       \n",
    "basic_path = os.path.join(*['aclImdb', 'test', 'pos'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_test = data_test.append({\n",
    "            'text': f.read(),\n",
    "            'target': 1\n",
    "        }, ignore_index=True)\n",
    "print('[info] test \\'pos\\' data loaded')\n",
    "\n",
    "basic_path = os.path.join(*['aclImdb', 'test', 'neg'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_test = data_test.append({\n",
    "            'text': f.read(),\n",
    "            'target': 0\n",
    "        }, ignore_index=True)\n",
    "print('[info] test \\'neg\\' data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = shuffle(data_train).reset_index(drop=True)\n",
    "data_test = shuffle(data_test).reset_index(drop=True)\n",
    "\n",
    "data_train.to_csv('aclImdb/train.csv', index=False)\n",
    "data_train.to_csv('aclImdb/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like many Americans, I was first introduced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE KING MAKER will doubtless be a success in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I work with children from 0  6 years old and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I was chairman of our college's coffeehou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember watching this on prime time when I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I feel totally ripped off. Someone needs to re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Having seen \"Triumph of the Will,\" I can only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>This was just another marvelous film of the Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>I've just visited Russian forum of our TV-chan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>SPOILER: The young lover, Jed, is kicked out b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text target\n",
       "0    Like many Americans, I was first introduced to...      1\n",
       "1    THE KING MAKER will doubtless be a success in ...      0\n",
       "2    I work with children from 0  6 years old and ...      1\n",
       "3    When I was chairman of our college's coffeehou...      1\n",
       "4    I remember watching this on prime time when I ...      0\n",
       "..                                                 ...    ...\n",
       "995  I feel totally ripped off. Someone needs to re...      0\n",
       "996  Having seen \"Triumph of the Will,\" I can only ...      0\n",
       "997  This was just another marvelous film of the Be...      1\n",
       "998  I've just visited Russian forum of our TV-chan...      0\n",
       "999  SPOILER: The young lover, Jed, is kicked out b...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeTransform(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tokenizer = tfds.features.text.Tokenizer()\n",
    "        X['text'] = X['text'].map(lambda a: [word for word in encoder.tokenize(a) if len(word) >= 3])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteemerTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, steemer=PorterStemmer()):\n",
    "        self.steemer = steemer\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X['text'] = X['text'].map(lambda a: ' '.join([self.steemer.stem(word) for word in a]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab_size=100, max_length=None):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if self.max_length is None:\n",
    "            longest_sentence = lambda a: len(a.split())\n",
    "            roi = max(X['text'], key=longest_sentence)\n",
    "            self.max_length = len(roi.split())\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X['text'] = X['text'].map(lambda a: one_hot(a, 100))\n",
    "        X['text'] = pad_sequences(X['text'], 1000, padding='post').tolist()\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tokenize', TokenizeTransform()),\n",
    "    ('steem', SteemerTransform(steemer=SnowballStemmer('russian'))),\n",
    "    ('vectorize', VectorizeTransformer(vocab_size=1000, max_length=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pipeline.fit_transform(data_train)\n",
    "data_test = pipeline.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data_train['text'].tolist(), dtype=np.int32)\n",
    "X_test = np.array(data_test['text'].tolist(), dtype=np.int32)\n",
    "\n",
    "y_train = data_train['target'].values.astype(np.int32)\n",
    "y_test = data_test['target'].values.astype(np.int32)\n",
    "\n",
    "X_valid = X_test[500:]\n",
    "y_valid = y_test[500:]\n",
    "X_test = X_test[:500]\n",
    "y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "    articles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in articles['дача'].items():\n",
    "    dataset = dataset.append({'text': v, 'target': 'дача'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вспоминаем работающие методы наших бабушек!\\nТ...</td>\n",
       "      <td>здоровье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Пора вставать на каблуки или проверить щитовид...</td>\n",
       "      <td>здоровье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Оказывается, существует специальная диета.\\n5 ...</td>\n",
       "      <td>здоровье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как выбрать зубную щетку и в чем разница между...</td>\n",
       "      <td>здоровье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Каждый третий в нашей стране страдает депресси...</td>\n",
       "      <td>здоровье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Хмель можно использовать не только в пивоварен...</td>\n",
       "      <td>дача</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Хмель – это красивое, декоративное растение с ...</td>\n",
       "      <td>дача</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Пепино называют в народе дынной грушей и груше...</td>\n",
       "      <td>дача</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Пак-чой – это разновидность капусты, родом из ...</td>\n",
       "      <td>дача</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Мокрицы – это не насекомые, а представители се...</td>\n",
       "      <td>дача</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    target\n",
       "0    Вспоминаем работающие методы наших бабушек!\\nТ...  здоровье\n",
       "1    Пора вставать на каблуки или проверить щитовид...  здоровье\n",
       "2    Оказывается, существует специальная диета.\\n5 ...  здоровье\n",
       "3    Как выбрать зубную щетку и в чем разница между...  здоровье\n",
       "4    Каждый третий в нашей стране страдает депресси...  здоровье\n",
       "..                                                 ...       ...\n",
       "495  Хмель можно использовать не только в пивоварен...      дача\n",
       "496  Хмель – это красивое, декоративное растение с ...      дача\n",
       "497  Пепино называют в народе дынной грушей и груше...      дача\n",
       "498  Пак-чой – это разновидность капусты, родом из ...      дача\n",
       "499  Мокрицы – это не насекомые, а представители се...      дача\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shuffle(dataset).reset_index(drop=True)\n",
    "X = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X['text'].tolist(), dtype=np.int32)\n",
    "y_train = X['target'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_train[:100]\n",
    "y_test = y_train[:100]\n",
    "\n",
    "X_valid = X_train[100:200]\n",
    "y_valid = y_train[100:200]\n",
    "\n",
    "X_train = X_train[200:]\n",
    "y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1000)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #layers.Embedding(100, 20, input_length=1000),\n",
    "    layers.Dense(126, input_shape=[1000], \\\n",
    "                activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 126)               126126    \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 127       \n",
      "=================================================================\n",
      "Total params: 126,253\n",
      "Trainable params: 126,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: -356.4022 - acc: 0.1767 - val_loss: -818.4118 - val_acc: 0.2100\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 0s 121us/sample - loss: -1314.9517 - acc: 0.1800 - val_loss: -1772.9922 - val_acc: 0.2100\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 0s 120us/sample - loss: -2418.9060 - acc: 0.1800 - val_loss: -3017.0802 - val_acc: 0.2100\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 0s 135us/sample - loss: -3895.7314 - acc: 0.1800 - val_loss: -4505.2830 - val_acc: 0.2100\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 0s 124us/sample - loss: -5481.3028 - acc: 0.1800 - val_loss: -6345.2695 - val_acc: 0.2100\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 0s 120us/sample - loss: -7608.4934 - acc: 0.1800 - val_loss: -8311.0908 - val_acc: 0.2100\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 0s 127us/sample - loss: -9952.4770 - acc: 0.1800 - val_loss: -10644.5927 - val_acc: 0.2100\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 0s 130us/sample - loss: -12676.7199 - acc: 0.1800 - val_loss: -13423.3505 - val_acc: 0.2100\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 0s 139us/sample - loss: -15661.1076 - acc: 0.1800 - val_loss: -16569.8840 - val_acc: 0.2100\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 0s 117us/sample - loss: -19332.1212 - acc: 0.1800 - val_loss: -19969.1745 - val_acc: 0.2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a51a29310>"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, verbose=1, batch_size=32, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
