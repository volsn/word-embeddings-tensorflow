{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vlsnk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "import os, sys\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'imdbEr.txt',\n",
       " 'test',\n",
       " 'test.csv',\n",
       " 'imdb.vocab',\n",
       " 'README',\n",
       " 'train',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the IMBD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.DataFrame(columns=['text', 'target'])\n",
    "data_test = pd.DataFrame(columns=['text', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] train 'pos' data loaded\n",
      "[info] train 'neg' data loaded\n",
      "[info] test 'pos' data loaded\n",
      "[info] test 'neg' data loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train data\n",
    "\"\"\"\n",
    "basic_path = os.path.join(*['aclImdb', 'train', 'pos'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_train = data_train.append({\n",
    "            'text': f.read(),\n",
    "            'target': 1\n",
    "        }, ignore_index=True)\n",
    "print('[info] train \\'pos\\' data loaded')\n",
    "        \n",
    "basic_path = os.path.join(*['aclImdb', 'train', 'neg'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_train = data_train.append({\n",
    "            'text': f.read(),\n",
    "            'target': 0\n",
    "        }, ignore_index=True)\n",
    "print('[info] train \\'neg\\' data loaded')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test data\n",
    "\"\"\"       \n",
    "basic_path = os.path.join(*['aclImdb', 'test', 'pos'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_test = data_test.append({\n",
    "            'text': f.read(),\n",
    "            'target': 1\n",
    "        }, ignore_index=True)\n",
    "print('[info] test \\'pos\\' data loaded')\n",
    "\n",
    "basic_path = os.path.join(*['aclImdb', 'test', 'neg'])\n",
    "for file in os.listdir(basic_path)[:500]:\n",
    "    with open(os.path.join(basic_path, file), 'r') as f:\n",
    "        data_test = data_test.append({\n",
    "            'text': f.read(),\n",
    "            'target': 0\n",
    "        }, ignore_index=True)\n",
    "print('[info] test \\'neg\\' data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = shuffle(data_train).reset_index(drop=True)\n",
    "data_test = shuffle(data_test).reset_index(drop=True)\n",
    "\n",
    "data_train.to_csv('aclImdb/train.csv', index=False)\n",
    "data_train.to_csv('aclImdb/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Okay, I've tried and I've tried, but I STILL D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitely spoilers in this review! I **adore*...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Much like the comedy duo of its title, \"The Su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know that the real story of Little Richard i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hail Bollywood and men Directors !&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I am stunned to discover the amount of fans th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>This movie is just not worth your time. Its re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Allow me to start this review by saying this: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Nightmare Weekend is proof positive that some ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I question the motive of the creators of this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text target\n",
       "0    Okay, I've tried and I've tried, but I STILL D...      0\n",
       "1    Definitely spoilers in this review! I **adore*...      1\n",
       "2    Much like the comedy duo of its title, \"The Su...      1\n",
       "3    I know that the real story of Little Richard i...      0\n",
       "4    Hail Bollywood and men Directors !<br /><br />...      0\n",
       "..                                                 ...    ...\n",
       "995  I am stunned to discover the amount of fans th...      0\n",
       "996  This movie is just not worth your time. Its re...      0\n",
       "997  Allow me to start this review by saying this: ...      0\n",
       "998  Nightmare Weekend is proof positive that some ...      0\n",
       "999  I question the motive of the creators of this ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeTransform(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tokenizer = tfds.features.text.Tokenizer()\n",
    "        X['text'] = X['text'].map(lambda a: [word for word in encoder.tokenize(a) if len(word) >= 3])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteemerTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, steemer=PorterStemmer()):\n",
    "        self.steemer = steemer\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X['text'] = X['text'].map(lambda a: ' '.join([self.steemer.stem(word) for word in a]))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocab_size=100, max_length=None):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if self.max_length is None:\n",
    "            longest_sentence = lambda a: len(a.split())\n",
    "            roi = max(X['text'], key=longest_sentence)\n",
    "            self.max_length = len(roi.split())\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X['text'] = X['text'].map(lambda a: one_hot(a, 100))\n",
    "        X['text'] = pad_sequences(X['text'], 1000, padding='post').tolist()\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tokenize', TokenizeTransform()),\n",
    "    ('steem', SteemerTransform(steemer=SnowballStemmer('russian'))),\n",
    "    ('vectorize', VectorizeTransformer(vocab_size=1000, max_length=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
