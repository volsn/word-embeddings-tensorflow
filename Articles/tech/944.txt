This week, Twitter has been inundated with pictures generated by ImageNet Roulette. The photos are typically of a person's face and feature a green box with a black and green label listing an automatically generated label for the person, based on the software's best guess of what social role they occupy. ImageNet Roulette is an art project created by Berlin-based developer Leif Ryge, working in collaboration with artist and researcher Trevor Paglen and AI researcher Kate Crawford. It's part of an exhibition called Training Humans, currently showing in the Osservatorio Fondazione Prada in Milan, which explores how datasets and automated systems represent and classify humans. ImageNet Roulette, a web extension of the exhibition, is designed to demonstrate it. But in practice it sucks, turning out mostly gibberish. Worse, when people of color put their images into it, the app can spit back out shockingly racist and vile labels based on their ethnicities. Ryge and Paglen's studio has not yet responded to a request for comment. Crawford acknowledged in a series of tweets earlier this week how bad AI is at interpreting pictures of humans — and how's that's the point of the project. "The labels come from WordNet, the images were scraped from search engines. The 'Person' category was rarely used or talked about. But it's strange, fascinating, and often offensive," Crawford wrote. "It reveals the deep problems with classifying humans — be it race, gender, emotions or characteristics. It's politics all the way down, and there's no simple way to 'debias' it." ImageNet, the system on which the app is built, is a research project created at Stanford University and Princeton University. It's an image dataset organized according to WordNet, a database created at Princeton of English nouns, verbs, adjectives, and adverbs. The WordNet database is where the labels come from. "ImageNet was created in 2009 as — and continues to be — an academic research project to help computers identi