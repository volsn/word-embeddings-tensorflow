Last March, within minutes of the Christchurch mosque attacks, footage from the shooter’s livestream began circulating on the meme-sharing app and site iFunny. The site’s users, predominantly white young men and teenage boys, declared the shooter a hero. They photoshopped him to look like Jesus. One user re-created the entire attack as a Minecraft simulation. And, according to a current moderator for iFunny, there wasn’t a thing he could do about it. “Our app was so filled to the brim with [reuploaded] footage from the livestream, I was actually losing sleep at night,” the moderator told BuzzFeed News. “Their screams were burned into my mind.” In the hours immediately following the attack, the site’s COO told him and the other volunteer moderators to leave up the footage of the shooting, as well as content that glorified the killer. Only days later did the site reverse course, under external pressure. “Moderators were not even allowed to remove all clips of the livestream from the app until certain governments started declaring possession of the footage a crime,” said the moderator, who requested anonymity to speak freely. An iFunny spokesperson denied that extremist content is allowed to remain on the site, saying that it is removed within a day of being reported: “All content of mass shootings is bannable as ‘death/gore’ if it shows victims or potential victims.” This week, authorities charged Justin Olsen, an 18-year-old Youngstown, Ohio, resident with threatening a federal officer for posts he made on a Discord server full of other iFunny users and which he advertised from an iFunny account full of memes calling for attacks on Planned Parenthood and a holy war between Christian and Muslims. Law enforcement seized 15 rifles, 10 semiautomatic pistols, and 10,000 rounds of ammunition from Olsen’s father’s home on Aug. 7, according to court documents made public this week. Said the moderator, “I sincerely fear the next El Paso–type shooter will come from the depths 